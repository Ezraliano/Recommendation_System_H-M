# -*- coding: utf-8 -*-
"""Submisssion Akhir Machine Learning Terapan.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14t5Tt9l7XQT0PjNVWB8CrGWnE-WKP9DR

## Import Library
"""

import pandas as pd
import numpy as np
import seaborn as sns
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.feature_extraction.text import TfidfVectorizer
import warnings
warnings.filterwarnings('ignore')
import matplotlib.pyplot as plt
from sklearn.metrics.pairwise import cosine_similarity

"""Deskripsi :
Mengimpor pustaka yang diperlukan untuk analisis data, visualisasi, preprocessing, dan modeling:
- pandas dan numpy untuk manipulasi data.
- seaborn dan matplotlib untuk visualisasi.
- sklearn.preprocessing untuk encoding dan standarisasi.
- TfidfVectorizer untuk ekstraksi fitur teks.
- cosine_similarity untuk menghitung kesamaan antar produk.
- warnings untuk mengabaikan peringatan yang tidak relevan.

Library yang diimpor menunjukkan bahwa kode ini akan melakukan analisis data, visualisasi, pra-pemrosesan, dan pembangunan sistem rekomendasi.

## Load Data
"""

hm1 = pd.read_csv('https://raw.githubusercontent.com/Ezraliano/Dataset_HM/refs/heads/main/handm.csv')
hm1.head()
hm1.tail()

"""Deskripsi
Memuat dataset H&M dari URL dan menampilkan 5 baris pertama dan terakhir untuk memeriksa struktur data.
Dataset berisi informasi produk seperti productId, price, colorName, mainCatCode, dll.

## Univariate Explorasi Data Analysis
"""

print(hm1.info())

"""Deskripsi : menampilkan informasi tentang jumlah baris, kolom, tipe data, dan memori yang digunakan."""

hm1.describe()

"""Deskripsi : memberikan statistik deskriptif (seperti rata-rata, minimum, maksimum) untuk kolom numerik."""

# Mengecek nilai yang hilang
print("\nJumlah Nilai yang Hilang per Kolom:")
print(hm1.isnull().sum())

"""Deskripsi : memeriksa jumlah nilai yang hilang di setiap kolom untuk mengetahui kualitas data."""

# 1. Identifikasi kolom numerik dan kategorikal
numeric_cols = ['price']
categorical_cols = ['stockState', 'comingSoon', 'colorName', 'isOnline', 'newArrival', 'mainCatCode']

print("Kolom Numerik:", numeric_cols)
print("Kolom Kategorikal:", categorical_cols)

"""Deskripsi :
- Kolom kategorikal dipilih untuk analisis distribusi dan encoding di langkah berikutnya.
- Pemisahan ini memudahkan analisis spesifik untuk setiap jenis data.
"""

# 2. Analisis Numerik: price
print("\nStatistik Deskriptif untuk Price:")
print(hm1['price'].describe())

"""Deskripsi :
- hm1['price'].describe() memberikan statistik seperti rata-rata, median, minimum, dan maksimum untuk kolom price.
"""

# Histogram untuk price
plt.figure(figsize=(8, 4))
sns.histplot(hm1['price'], kde=True, bins=20)
plt.title('Distribusi Harga (Price)')
plt.xlabel('Harga ($)')
plt.ylabel('Frekuensi')
plt.show()

"""Deskripsi :
- Histogram (sns.histplot) menunjukkan distribusi harga, dengan kurva KDE (Kernel Density Estimation) untuk memperkirakan kepadatan distribusi kolom price

"""

# Boxplot untuk price
plt.figure(figsize=(8, 4))
sns.boxplot(x=hm1['price'])
plt.title('Boxplot Harga (Price)')
plt.xlabel('Harga ($)')
plt.show()

"""Deskripsi :
- Boxplot (sns.boxplot) mengidentifikasi outlier dan memberikan gambaran tentang penyebaran data (quartiles).
"""

# 3. Analisis Kategorikal
for col in categorical_cols:
    print(f"\nDistribusi untuk kolom: {col}")
    print(hm1[col].value_counts(dropna=False))

    # Count plot (batasi jika terlalu banyak kategori)
    plt.figure(figsize=(10, 5))
    if hm1[col].nunique() <= 20:
        sns.countplot(y=hm1[col], order=hm1[col].value_counts().index[:20])
        plt.title(f'Distribusi {col}')
        plt.xlabel('Jumlah')
        plt.ylabel(col)
        plt.show()
    else:
        print(f"Kolom {col} memiliki terlalu banyak kategori ({hm1[col].nunique()}), visualisasi dilewati.")

"""Deskripsi :
- Untuk setiap kolom kategorikal, value_counts(dropna=False) menampilkan distribusi nilai, termasuk nilai yang hilang.
- sns.countplot membuat visualisasi batang untuk kolom dengan jumlah kategori unik â‰¤ 20, menunjukkan frekuensi setiap kategori.
- Jika jumlah kategori > 20, visualisasi dilewati untuk menghindari plot yang terlalu padat.

Alasan :
- Analisis ini mengungkapkan distribusi kategori, misalnya, apakah beberapa warna atau kategori produk mendominasi
- Batasan 20 kategori mencegah visualisasi yang tidak informatif untuk kolom seperti colorName yang mungkin memiliki banyak nilai unik.
- Informasi ini penting untuk menentukan kolom mana yang relevan untuk encoding.

## Data Preparation
"""

# Langkah 1: Menangani Missing Values
print("Jumlah Missing Values Sebelum Preprocessing:")
print(hm1.isnull().sum())

# details: Isi dengan string kosong
hm1['details'].fillna('', inplace=True)

# materials: Isi dengan string kosong
hm1['materials'].fillna('', inplace=True)

# colorShades: Isi dengan 'Unknown'
hm1['colorShades'].fillna('Unknown', inplace=True)

# Verifikasi missing values setelah penanganan
print("\nJumlah Missing Values Setelah Penanganan:")
print(hm1.isnull().sum())

"""Deskripsi :
- Pertama, kode memeriksa jumlah nilai yang hilang untuk setiap kolom.
- Kolom details dan materials diisi dengan string kosong karena ini adalah kolom teks, dan string kosong cocok untuk analisis teks seperti TF-IDF.
- Kolom colorShades diisi dengan 'Unknown' untuk mengisi missing values yang ada pada kolom ini
- Pilihan pengisian (string kosong untuk teks, 'Unknown' untuk kategori) sesuai dengan sifat kolom.
"""

# Langkah 2: Memeriksa dan Menghapus Duplikasi
print("\nJumlah Duplikasi berdasarkan productId:", hm1['productId'].duplicated().sum())
hm1 = hm1.drop_duplicates(subset=['productId'], keep='first')

"""Deskripsi :
- hm1['productId'].duplicated().sum() menghitung jumlah baris dengan productId yang sama.
- drop_duplicates menghapus duplikasi berdasarkan productId, menyimpan baris pertama yang ditemukan.

Alasan :
- Menghapus duplikasi memastikan bahwa setiap produk hanya diwakili sekali, yang penting untuk sistem rekomendasi

"""

# Langkah 3: Menghapus Kolom Tidak Relevan
cols_to_drop = ['Unnamed: 0', 'url', 'productName']
# Periksa apakah kolom konstan
for col in ['isOnline', 'comingSoon', 'stockState']:
    if hm1[col].nunique() == 1:
        cols_to_drop.append(col)
        print(f"Kolom {col} nilai konstan, akan dihapus.")

hm1 = hm1.drop(columns=cols_to_drop, errors='ignore')

"""Deskripsi :
 - Kolom seperti Unnamed: 0 (indeks tambahan), url, dan productName dianggap tidak relevan untuk sistem rekomendasi dan dimasukkan ke daftar cols_to_drop.
 - Kode memeriksa apakah kolom isOnline, comingSoon, dan stockState memiliki nilai konstan (satu nilai unik). Jika ya, kolom tersebut ditambahkan ke cols_to_drop karena tidak memberikan informasi tambahan.
 - hm1.drop menghapus kolom-kolom ini, dengan errors='ignore' untuk mencegah error jika kolom tidak ada

 Alasan :
 - Menghapus kolom yang tidak relevan atau konstan mengurangi dimensi data dan meningkatkan efisiensi.
"""

# Langkah 4: Encoding Variabel Kategorikal
categorical_cols = ['colorName', 'mainCatCode', 'brandName', 'colorShades', 'newArrival']
encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
encoded_cats = encoder.fit_transform(hm1[categorical_cols])
encoded_cats_df = pd.DataFrame(encoded_cats, columns=encoder.get_feature_names_out(categorical_cols))
# Gabungkan dengan dataset
hm1_encoded = pd.concat([hm1.reset_index(drop=True), encoded_cats_df.reset_index(drop=True)], axis=1)
# Hapus kolom kategorikal asli
hm1_encoded = hm1_encoded.drop(columns=categorical_cols)

"""Deskripsi :
- Kolom kategorikal baru dipilih: colorName, mainCatCode, brandName, colorShades, newArrival.
- OneHotEncoder mengubah setiap kategori menjadi kolom biner (0 atau 1). Parameter sparse_output=False menghasilkan array padat, dan handle_unknown='ignore' menangani kategori baru di data uji.
- Hasil encoding disimpan dalam DataFrame encoded_cats_df dengan nama kolom yang mencerminkan kategori.
- DataFrame asli (hm1) digabungkan dengan kolom hasil encoding, dan kolom kategorikal asli dihapus.

Alasan :
- One-Hot Encoding cocok untuk kolom kategorikal tanpa urutan, seperti warna atau merek.
- Penghapusan kolom asli mencegah redundansi dan menjaga data tetap bersih.
- Encoding meningkatkan dimensi data, yang bisa menjadi tantangan untuk dataset besar.
"""

# Langkah 5: Standarisasi Kolom Numerik (price)
scaler = StandardScaler()
hm1_encoded['price_scaled'] = scaler.fit_transform(hm1[['price']])

"""Deskripsi :
- StandardScaler menstandarisasi price sehingga memiliki rata-rata 0 dan standar deviasi 1.
- Kolom hasilnya (price_scaled) ditambahkan ke hm1_encoded.

Alasan :
- Standarisasi penting untuk algoritma berbasis jarak seperti cosine similarity, agar fitur numerik tidak mendominasi karena skala yang berbeda.
- Hanya price yang distandarisasi karena ini satu-satunya kolom numerik.
"""

# Langkah 6: Feature Engineering
# - Buat segmen harga
hm1_encoded['price_segment'] = pd.cut(hm1['price'],
                                     bins=[0, 30, 50, float('inf')],
                                     labels=['Murah', 'Menengah', 'Premium'])

# - Ekstraksi TF-IDF untuk details dan materials
tfidf = TfidfVectorizer(max_features=100, stop_words='english')
tfidf_details = tfidf.fit_transform(hm1['details'])
tfidf_details_df = pd.DataFrame(tfidf_details.toarray(),
                                columns=[f"details_{f}" for f in tfidf.get_feature_names_out()])

tfidf_materials = tfidf.fit_transform(hm1['materials'])
tfidf_materials_df = pd.DataFrame(tfidf_materials.toarray(),
                                  columns=[f"materials_{f}" for f in tfidf.get_feature_names_out()])

# Gabungkan fitur TF-IDF
hm1_encoded = pd.concat([hm1_encoded.reset_index(drop=True),
                         tfidf_details_df.reset_index(drop=True),
                         tfidf_materials_df.reset_index(drop=True)], axis=1)

"""Deskripsi :
- pd.cut mengelompokkan harga ke dalam tiga segmen: Murah (â‰¤$30), Menengah ($30â€“$50), dan Premium (>$50).
- Fitur baru price_segment ditambahkan ke hm1_encoded.
- TfidfVectorizer mengubah teks dalam details dan materials menjadi vektor numerik berdasarkan pentingnya kata (TF-IDF). Parameter max_features=100 membatasi jumlah kata, dan stop_words='english' menghapus kata umum seperti "the".
- Hasilnya adalah matriks sparse yang diubah menjadi DataFrame (tfidf_details_df dan tfidf_materials_df) dengan nama kolom yang mencerminkan kata.
- DataFrame ini digabungkan dengan hm1_encoded.
"""

# Langkah 7: Menangani Kolom colors
hm1_encoded = hm1_encoded.drop(columns=['colors'], errors='ignore')

"""Deskripsi :
 - Kolom colors dihapus karena redundan dengan colorName.
 - Parameter errors='ignore' mencegah error jika kolom tidak ada.
"""

# Gabungkan semua fitur
hm1_encoded = pd.concat([
    hm1[['productId', 'price']].reset_index(drop=True),
    hm1_encoded[['price_scaled']].reset_index(drop=True),
    encoded_cats_df.reset_index(drop=True),
    tfidf_details_df.reset_index(drop=True),
    tfidf_materials_df.reset_index(drop=True)
], axis=1)

"""Deskripsi :
 - Dataset akhir (hm1_encoded) mencakup productId, price, price_scaled, fitur kategorikal yang diencode, dan fitur TF-IDF dari details dan materials.
 - reset_index(drop=True) memastikan indeks selaras saat penggabungan.

Alasan :
- Penggabungan ini menciptakan dataset lengkap untuk sistem rekomendasi.
- Menyimpan productId dan price memungkinkan pelacakan produk dan filtering berdasarkan harga.
"""

# Simpan informasi produk untuk output rekomendasi
hm1_info = hm1[['productId', 'price', 'colorName', 'mainCatCode', 'brandName', 'newArrival']].copy()

"""Deskripsi :
- DataFrame hm1_info menyimpan kolom yang relevan untuk menampilkan rekomendasi (ID, harga, warna, kategori, merek, status baru)
- .copy() memastikan bahwa ini adalah salinan independen dari hm1.

## Modelling
"""

# Langkah 1: Pilih fitur untuk content-based filtering
feature_cols = [col for col in hm1_encoded.columns if col not in ['productId', 'price']]
feature_matrix = hm1_encoded[feature_cols].values

"""Deskripsi :    
- Feature_cols mencakup semua kolom kecuali productId dan price, karena ini adalah fitur untuk menghitung kesamaan
- Feature_matrix adalah array NumPy dari fitur-fitur ini.
"""

# Langkah 2: Hitung cosine similarity
similarity_matrix = cosine_similarity(feature_matrix)

"""Deskripsi :    
- Cosine_similarity menghitung kesamaan antar produk berdasarkan vektor fitur, menghasilkan matriks kesamaan.
"""

# Langkah 3: Fungsi untuk mendapatkan rekomendasi
def get_recommendations(product_id, num_recommendations=5, price_range=None):
    idx = hm1_encoded.index[hm1_encoded['productId'] == product_id].tolist()
    if not idx:
        return "Product ID tidak ditemukan."
    idx = idx[0]

    # Ambil skor kesamaan
    sim_scores = list(enumerate(similarity_matrix[idx]))

    # Filter berdasarkan price_range jika ditentukan
    if price_range is not None:
        target_price = hm1_encoded.loc[idx, 'price']
        sim_scores = [(i, s) for i, s in sim_scores
                      if abs(hm1_encoded.loc[i, 'price'] - target_price) <= price_range]

    # Urutkan berdasarkan skor kesamaan
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:num_recommendations+1]

    # Ambil indeks produk yang direkomendasikan
    product_indices = [i[0] for i in sim_scores]

    # Kembalikan informasi produk
    return hm1_info.iloc[product_indices][['productId', 'price', 'colorName', 'mainCatCode', 'brandName', 'newArrival']]

"""Deskripsi :    
- Fungsi mengambil product_id, jumlah rekomendasi (num_recommendations), dan batas harga (price_range).
- Mencari indeks produk berdasarkan productId. Jika tidak ditemukan, mengembalikan pesan error
- Mengambil skor kesamaan dari similarity_matrix untuk produk tersebut.
- Jika price_range diberikan, menyaring produk yang harganya berada dalam kisaran Â±price_range dari harga produk target.
- Mengurutkan skor kesamaan, mengambil num_recommendations produk teratas (kecuali produk itu sendiri), dan mengembalikan informasi produk dari hm1_info.
"""

# Langkah 4: Contoh rekomendasi
sample_product_ids = hm1_encoded['productId'].head(3).tolist()
for pid in sample_product_ids:
    print(f"\nRekomendasi untuk productId={pid} (dengan price_range=10):")
    print(get_recommendations(product_id=pid, num_recommendations=5, price_range=10))

"""Deskripsi :    
- Mengambil tiga productId pertama dari hm1_encoded.
- Untuk setiap ID, memanggil get_recommendations dengan price_range=10 dan menampilkan hasilnya.

## Evaluasi Model
"""

# Langkah 1: Pilih produk contoh dari kategori berbeda
# Memilih productId dari beberapa mainCatCode yang representatif
sample_products = hm1_info.groupby('mainCatCode').head(1)[['productId', 'mainCatCode']].head(3)
sample_product_ids = sample_products['productId'].tolist()
sample_categories = sample_products['mainCatCode'].tolist()

"""Deskripsi :    
- Memilih satu produk dari tiga kategori berbeda menggunakan groupby('mainCatCode').head(1)
"""

# Langkah 2: Tampilkan rekomendasi untuk setiap produk contoh
for pid, cat in zip(sample_product_ids, sample_categories):
    print(f"\n=== Rekomendasi untuk productId={pid} (Kategori: {cat}) ===")
    print("Produk Asli:")
    # Include 'details' and 'materials' when creating hm1_info
    print(hm1[hm1['productId'] == pid][['productId', 'price', 'colorName', 'mainCatCode', 'brandName', 'newArrival', 'details', 'materials']])
    print("\nProduk yang Direkomendasikan (dengan price_range=10):")

    # Get recommendations and similarity scores
    idx = hm1_encoded.index[hm1_encoded['productId'] == pid].tolist()[0]
    sim_scores = list(enumerate(similarity_matrix[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:6]

    # Fix: Extract product indices and similarity scores correctly
    product_indices = [i for i, s in sim_scores]
    similarity_scores = [s for i, s in sim_scores]

    recommendations = hm1_info.iloc[product_indices][['productId', 'price', 'colorName', 'mainCatCode', 'brandName', 'newArrival']]
    recommendations['similarity_score'] = similarity_scores

    print(recommendations)
    print("\nInterpretasi:")
    # Analisis kualitatif
    same_category = (recommendations['mainCatCode'] == cat).sum()
    similar_colors = recommendations['colorName'].str.contains(hm1_info.loc[hm1_info['productId'] == pid, 'colorName'].iloc[0], case=False, na=False).sum()
    print(f"- {same_category}/5 rekomendasi memiliki kategori yang sama ({cat}).")
    print(f"- {similar_colors}/5 rekomendasi memiliki warna serupa.")
    print(f"- Rentang harga rekomendasi: ${recommendations['price'].min():.2f} - ${recommendations['price'].max():.2f}")
    print(f"- Skor kesamaan: {recommendations['similarity_score'].min():.3f} - {recommendations['similarity_score'].max():.3f}")

"""Deskripsi :    
- Menampilkan informasi produk asli, termasuk details dan materials.
- Menghitung rekomendasi dengan cara yang sama seperti fungsi sebelumnya, tetapi menyertakan skor kesamaan.
- Menganalisis rekomendasi secara kualitatif, menghitung :    
  - Jumlah rekomendasi dalam kategori yang sama.
  - Jumlah rekomendasi dengan warna serupa (menggunakan pencocokan string).
  - Rentang harga rekomendasi.
  - Rentang skor kesamaan.

Alasan :    
- Analisis ini mengevaluasi kualitas rekomendasi berdasarkan kategori, warna, dan harga.
- Penyertaan details dan materials memberikan konteks tambahan tentang produk asli.
- Interpretasi kualitatif membantu memahami apakah sistem merekomendasikan produk yang relevan.
"""

# Langkah 3: Analisis distribusi skor kesamaan
plt.figure(figsize=(8, 4))
sns.histplot(similarity_matrix.flatten(), bins=50, kde=True)
plt.title('Distribusi Skor Kesamaan (Cosine Similarity)')
plt.xlabel('Skor Kesamaan')
plt.ylabel('Frekuensi')
plt.show()

"""Deskripsi :    
- similarity_matrix.flatten() mengubah matriks kesamaan menjadi array satu dimensi.
- sns.histplot membuat histogram dengan 50 bin dan kurva KDE untuk menunjukkan distribusi skor kesamaan.

Alasan :    
- Histogram ini menunjukkan apakah produk cenderung sangat mirip (skor mendekati 1) atau berbeda (skor mendekati 0).
- Distribusi yang baik memiliki campuran skor tinggi dan rendah, menunjukkan bahwa model dapat membedakan produk.
"""